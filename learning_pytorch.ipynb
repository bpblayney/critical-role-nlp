{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cuda:0 but got device cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0c7c9652f3f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cuda:0 but got device cpu"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5,3], dtype=torch.float32, device=device, requires_grad=True)\n",
    "y = torch.Tensor([2,1])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5,3], dtype=torch.float32, device=device, requires_grad=True)\n",
    "y = torch.tensor([2,1], dtype=torch.float32, device=device, requires_grad=True)\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5]) tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]) tensor([[0.3701, 0.3684, 0.0544, 0.5988, 0.5395],\n",
      "        [0.1707, 0.9708, 0.0945, 0.4065, 0.1974]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "y = torch.rand([2,5])\n",
    "print(x.shape, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3701, 0.3684, 0.0544, 0.5988, 0.5395, 0.1707, 0.9708, 0.0945, 0.4065,\n",
       "         0.1974]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(start=0.1, end=1, steps=10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0305, 0.9668, 0.2055, 0.5282, 0.8413]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(size=(1,5)).uniform_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([False,  True,  True,  True])\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.arange(4)\n",
    "print(tensor)\n",
    "print(tensor.bool())\n",
    "print(tensor.short())\n",
    "print(tensor.long())\n",
    "print(tensor.float())\n",
    "print(tensor.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.zeros((5,5))\n",
    "tensor = torch.from_numpy(np_array)\n",
    "np_array_back = tensor.numpy()\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 10.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([9,8,7])\n",
    "\n",
    "z1 = torch.empty(3)\n",
    "torch.add(x,y,out=z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = torch.add(x, y)\n",
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8, -6, -4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1111, 0.2500, 0.4286])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.true_divide(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace operations\n",
    "t = torch.zeros(3)\n",
    "t.add_(x) # _ signifies inplace; also returns result\n",
    "t += x # t = t + x will not be inplace\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.pow(2)\n",
    "z = x ** 2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8048, 0.3464, 0.6343, 0.3774, 0.3717],\n",
       "        [0.6451, 0.8586, 0.8056, 0.9452, 0.1954]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand((2,5))\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2918, 1.5011, 1.2975],\n",
       "        [1.8299, 2.1756, 1.7424]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.rand((5,3))\n",
    "x3 = torch.mm(x1, x2)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2918, 1.5011, 1.2975],\n",
       "        [1.8299, 2.1756, 1.7424]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.mm(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 30])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch matrix multiplication\n",
    "batch = 32\n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "tensor1 = torch.rand((batch,n,m))\n",
    "tensor2 = torch.rand((batch,m,p))\n",
    "\n",
    "out_bmm = torch.bmm(tensor1, tensor2) # matrix mult across the appropriate dim (out (batch, n, p))\n",
    "out_bmm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.3835,  -4.7586,  -9.4987, -14.4273, -19.7072],\n",
       "        [  0.8517,  -4.7827,  -9.7003, -14.7938, -19.7391],\n",
       "        [  0.8542,  -4.3145,  -9.1017, -14.6758, -19.9026],\n",
       "        [  0.8664,  -4.7841,  -9.8909, -14.7451, -19.4490],\n",
       "        [  0.9881,  -4.1576,  -9.1309, -14.8459, -19.6225]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting\n",
    "x1 = torch.rand((5,5))\n",
    "x2 = torch.arange(5) # expanded in the subtraction to have 5 rows where each row is the same\n",
    "x1 - 5*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other useful tensor operations\n",
    "torch.sum(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices = torch.max(x, dim=0)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([7, 8, 9]),\n",
       "indices=tensor([2, 1, 0]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(y,dim=0,descending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(x, min=0, max=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(x,min=0) # this is just ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "torch.Size([10])\n",
      "tensor([0.5842, 0.0946, 0.4091, 0.1546, 0.4195, 0.8964, 0.3115, 0.2267, 0.5685,\n",
      "        0.3963])\n",
      "tensor([2, 5, 8])\n",
      "tensor([[0.3966, 0.3297, 0.0121, 0.5839, 0.9605],\n",
      "        [0.4165, 0.7195, 0.1293, 0.1870, 0.7970],\n",
      "        [0.4029, 0.8183, 0.5800, 0.4022, 0.7884]])\n",
      "tensor([0.7970, 0.3966])\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Tensor Indexing\n",
    "batch_size = 10\n",
    "features = 25\n",
    "x = torch.rand((batch_size, features))\n",
    "\n",
    "print(x[0].shape)\n",
    "print(x[:,0].shape)\n",
    "print(x[2,0:10])\n",
    "\n",
    "x[0,0] = 100\n",
    "\n",
    "# Fancy indexing\n",
    "x = torch.arange(10)\n",
    "indices = [2,5,8]\n",
    "print(x[indices])\n",
    "\n",
    "x = torch.rand((3,5))\n",
    "rows = torch.tensor([1,0])\n",
    "cols = torch.tensor([4,0])\n",
    "print(x)\n",
    "print(x[rows,cols]) # 2 elements\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x[(x<2) & (x>8)])\n",
    "print(x[x.remainder(2) == 0])\n",
    "\n",
    "print(torch.where(x>5, x, x*2)) # if x > 5 stay as x else multiply by 2\n",
    "\n",
    "print(torch.tensor([0,0,1,2,2,3,4]).unique())\n",
    "print(x.ndimension())\n",
    "print(x.numel()) # number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([2, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Tensor reshaping\n",
    "\n",
    "x = torch.arange(9)\n",
    "x_3x3 = x.view(3,3)\n",
    "print(x_3x3)\n",
    "x_3x3 = x.reshape(3,3) # safe bet, makes a copy, can have performance loss\n",
    "\n",
    "y= x_3x3.t()\n",
    "print(y.contiguous().view(9))\n",
    "print(x)\n",
    "\n",
    "x1 = torch.rand((2,5))\n",
    "x2 = torch.rand((2,5))\n",
    "print(torch.cat((x1,x2),dim=0).shape)\n",
    "print(torch.cat((x1,x2),dim=1).shape)\n",
    "print(x1.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch,-1)\n",
    "print(z.shape)\n",
    "z = x.permute(0, 2, 1) # transpose is a special case of permute\n",
    "print(z.shape)\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x.shape)\n",
    "print(x.unsqueeze(0).shape)\n",
    "print(x.unsqueeze(1).shape)\n",
    "\n",
    "x = torch.arange(10).unsqueeze(0).unsqueeze(1) # 1x1x10\n",
    "z = x.squeeze(1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # ReLU tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10, 512])\n",
      "torch.Size([30, 10, 64])\n",
      "torch.Size([64, 10, 30])\n",
      "torch.Size([30, 10, 30])\n",
      "torch.Size([30, 10, 30])\n",
      "torch.Size([30, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "n_words_source = 30\n",
    "n_words_target = 30\n",
    "batch_size = 10\n",
    "dim_model = 512\n",
    "dim_values = 64\n",
    "dim_keys = 64\n",
    "n_heads = 8\n",
    "x = torch.rand((n_words_target, batch_size, dim_model)) # (n_words, batch_size, dim_model)\n",
    "#values = torch.rand((batch_size, n_words_source, dim_model))\n",
    "\n",
    "values_projected = nn.Linear(dim_model, dim_values, bias=False)\n",
    "keys_projected = nn.Linear(dim_model, dim_keys, bias=False)\n",
    "queries_projected = nn.Linear(dim_model, dim_keys, bias=False)\n",
    "\n",
    "print(x.shape)\n",
    "values = values_projected(x) # (n_words, batch_size, dim_values)\n",
    "keys = keys_projected(x)\n",
    "queries = queries_projected(x)\n",
    "print(values.shape)\n",
    "print(keys.permute(2,1,0).shape)\n",
    "\n",
    "scaled = torch.einsum('ibj,jbk->ibk', queries, keys.permute(2,1,0)) / (dim_keys ** (1/2))\n",
    "print(scaled.shape)\n",
    "# every row of the word x word needs to sum to 1\n",
    "softmaxed = F.softmax(scaled, dim=2)\n",
    "print(softmaxed.shape)\n",
    "out = torch.einsum('ibj,jbk->ibk', softmaxed, values)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10, 512])\n",
      "torch.Size([30, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "w_o = nn.Linear(n_heads*dim_values, dim_model, bias=False)\n",
    "\n",
    "concatenated_attn_heads = torch.cat([out for _ in range(n_heads)], dim=2)\n",
    "print(concatenated_attn_heads.shape)\n",
    "z = w_o(concatenated_attn_heads)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7373, 0.1394, 0.1233],\n",
       "        [0.1155, 0.3117, 0.5728]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2997cb1c5351>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_words_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_words_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_head_attention_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   3822\u001b[0m             \u001b[0m_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3823\u001b[0m             \u001b[0m_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3824\u001b[1;33m             \u001b[0m_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3825\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_b\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3826\u001b[0m                 \u001b[0m_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "queries = torch.rand((n_words_target, batch_size, dim_model)) # (n_words, batch_size, dim_model)\n",
    "keys = torch.rand((n_words_source, batch_size, dim_model))\n",
    "values = torch.rand((n_words_source, batch_size, dim_model))\n",
    "F.multi_head_attention_forward(queries, keys, values, dim_model, 8, None, None, None, None, None, 0, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 30, 512])\n",
      "torch.Size([8, 30, 64])\n",
      "torch.Size([8, 30, 30])\n",
      "torch.Size([8, 30, 64])\n"
     ]
    }
   ],
   "source": [
    "queries = torch.rand((batch_size, n_words_source, dim_model))\n",
    "keys = torch.rand((batch_size, n_words_source, dim_model))\n",
    "values = torch.rand((batch_size, n_words_source, dim_model))\n",
    "print(values.shape)\n",
    "values = values_projected(values) # (batch_size, n_words_source, dim_values)\n",
    "keys = keys_projected(keys) # (batch_size, n_words_source, dim_values)\n",
    "queries = queries_projected(queries) # (batch_size, n_words_source, dim_values)\n",
    "print(values.shape)\n",
    "\n",
    "scaled = torch.bmm(queries, keys.permute(0, 2, 1)) / (dim_keys ** (1/2)) # (batch_size, n_words, n_words)\n",
    "print(scaled.shape)\n",
    "out = torch.bmm(F.softmax(scaled, dim=2), values) # attention (batch_size, n_words, dim_values)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
    "        output = torch.matmul(attn, v)\n",
    "\n",
    "        return output, attn\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model, bias=False)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "        sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n",
    "\n",
    "        residual = q\n",
    "\n",
    "        # Pass through the pre-attention projection: b x lq x (n*dv)\n",
    "        # Separate different heads: b x lq x n x dv\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        # Transpose for attention dot product: b x n x lq x dv\n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)   # For head axis broadcasting.\n",
    "\n",
    "        q, attn = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        # Transpose to move the head dimension back: b x lq x n x dv\n",
    "        # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)\n",
    "        q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1)\n",
    "        q = self.dropout(self.fc(q))\n",
    "        q += residual\n",
    "\n",
    "        q = self.layer_norm(q)\n",
    "\n",
    "        return q, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # ReLU tanh\n",
    "from torch.utils.data import DataLoader # Easier dataset management\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms # transformations we can perform on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create fully connected network\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__() # calls initialization method of the parent class (nn.Module)\n",
    "        self.fc1 = nn.Linear(input_size, 50) # 50 nodes in hidden layer\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = NN(784, 10)\n",
    "x = torch.randn(64, 784) #64 examples simultaneously (minibatch size)\n",
    "\n",
    "print(model(x).shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda'if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_dataset = datasets.MNIST(root='dataset/', train=True, transform = transforms.ToTensor(), download=True ) #transforms converts it from numpy to tensor\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) # shuffle each epoch\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform = transforms.ToTensor(), download=True ) #transforms converts it from numpy to tensor\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True) # shuffle each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        print(data.shape) # (64,1,28,28) 1 channel, 28x28 pixels\n",
    "        data = data.reshape(data.shape[0], -1) # Keep 64, then flatten all the others\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets) # targets are the correct labels, scores are the predictions\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # set all gradients to 0 foreach batch so don't store from previous forward props\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step() # gradient descent or adam step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 6116 / 60000 with accuracy 10.19\n",
      "Got 1024 / 10000 with accuracy 10.24\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # don't need to actually compute gradients in calculations\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0],-1)\n",
    "            scores=model(x)\n",
    "            _, predictions = scores.max(dim=1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "        \n",
    "    model.train()\n",
    "\n",
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
